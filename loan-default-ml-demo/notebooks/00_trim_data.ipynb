{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c3a50c-f394-48d0-b188-658dea9aa7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Trimmed shape: (443579, 151)\n",
      "‚úÖ Saved parquet OK: (443579, 151)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "raw_csv   = Path(\"../data/raw/accepted_2007_to_2018Q4.csv\")\n",
    "trim_csv  = Path(\"../data/raw/accepted_2017.csv\")\n",
    "trim_pq   = Path(\"../data/raw/accepted_2017.parquet\")\n",
    "\n",
    "# 1) Load the full LendingClub file\n",
    "df = pd.read_csv(raw_csv, low_memory=False)\n",
    "\n",
    "# 2) Keep only 2017 vintages (fully-seasoned loans)\n",
    "df_2017 = df[df[\"issue_d\"].str.contains(\"2017\", na=False)].copy()\n",
    "print(\"‚úÖ Trimmed shape:\", df_2017.shape)\n",
    "\n",
    "# 3) Save a lightweight CSV and a compact Parquet\n",
    "df_2017.to_csv(trim_csv, index=False)\n",
    "\n",
    "# Optimise string columns to category before Parquet\n",
    "for col in df_2017.select_dtypes(\"object\"):\n",
    "    df_2017[col] = df_2017[col].astype(\"category\")\n",
    "\n",
    "df_2017.to_parquet(trim_pq, compression=\"snappy\")\n",
    "print(\"‚úÖ Saved parquet OK:\", df_2017.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72906888-1df1-4f25-80c0-3ee41940964a",
   "metadata": {},
   "source": [
    "## üìù Why re-trim to 2017 only?\n",
    "\n",
    "After analysing default rates, I found late-2018 loans show < 1 % charge-off, while 2017 loans are ~6‚Äì11 %.  \n",
    "This gap exists because the public LendingClub snapshot was taken in early 2019, so many 2018 loans hadn‚Äôt had time to default.\n",
    "\n",
    "By limiting the dataset to 2017 only, every loan has ‚â• 24 months of observed performance, giving a consistent default rate across the cohort.\n",
    "\n",
    "**Next steps (in 01_eda and beyond)**\n",
    "\n",
    "1. Clean & engineer features on the 2017 data.\n",
    "2. Re-run feature selection (leak-free) and save `feature_lists_v3.pkl`.\n",
    "3. Perform a time-based split 70/30 split (train on loans ‚â§ 2017-09-01; test on loans > 2017-09-01) and save `train_v2` / `test_v2`.\n",
    "4. Fit baseline Logistic Regression again, then return to trying Gradient Boosting / XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
